{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JwRVioo_9xo-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29dfd88c-06f4-4747-fee0-dfd2e5f1fdd6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "imagem \n",
            "\n",
            "Temos a seguinte classe que representa um usuário no nosso sistema:\n",
            "\n",
            "java\n",
            "\n",
            "Para salvar um novo usuário, várias validações são feitas, como por exemplo: Ver se o nome só contém letras, [**o CPF só números**] e ver se o usuário possui no mínimo 18 anos. Veja o método que faz essa validação:\n",
            "\n",
            "java \n",
            "\n",
            "Suponha agora que eu tenha outra classe, a classe `Produto`, que contém um atributo nome e eu quero fazer a mesma validação que fiz para o nome do usuário: Ver se só contém letras. E aí? Vou\n"
          ]
        }
      ],
      "source": [
        "# importando o corpus (base de texto para o corretor)\n",
        "\n",
        "with open('artigos.txt', 'r') as f:\n",
        "  artigos = f.read()\n",
        "\n",
        "print(artigos[:500])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# precisamos descobrir quantas palavras temos no corpus\n",
        "# separando o texto em tokens com método split (tokenização)\n",
        "texto_exemplo = 'Olá, tudo bem?'\n",
        "tokens = texto_exemplo.split()\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbxKGnp1nsrl",
        "outputId": "8fee74ee-07b3-49ea-d448-a410680ad0a3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Olá,', 'tudo', 'bem?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuZ6fqk3py81",
        "outputId": "e53b5d62-7f7e-418e-868b-153fb5ee43e1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importando módulo nltk (natural lenguage toolkit)\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohx39jYqrxZJ",
        "outputId": "fe0018c9-051b-4013-ba13-f8770d4a2016"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# separando palavras da pontuação dentro da lista\n",
        "palavras_separadas = nltk.tokenize.word_tokenize(texto_exemplo)\n",
        "print(palavras_separadas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luB30JSkqFOz",
        "outputId": "cc610c8a-97c1-422d-ebbe-48921588b3e0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Olá', ',', 'tudo', 'bem', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(palavras_separadas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjGa9Zz9rqDP",
        "outputId": "5b05e20b-fe1d-42e2-8455-8bc26a6e1289"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# método isalpha() retorna booleano se contém somente caractere alfabético\n",
        "'palavra'.isalpha()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDseLzNPtG0r",
        "outputId": "7b2524f6-180d-4718-dd7b-7ac1d5f3f987"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'.'.isalpha()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MIueBgNt7-z",
        "outputId": "32f76087-4859-4394-96af-cb2e79bed1c5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# função para separar palavras de pontuações - nova lista somente com palavras\n",
        "\n",
        "def separa_palavras(lista_tokens):\n",
        "  lista_palavras = []\n",
        "  for token in lista_tokens:\n",
        "    if token.isalpha():\n",
        "      lista_palavras.append(token)\n",
        "  return lista_palavras\n",
        "\n",
        "separa_palavras(palavras_separadas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbQGDsCNspmF",
        "outputId": "b7a321d2-c2c3-42ab-83d9-af6225eaee8c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Olá', 'tudo', 'bem']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# executando a técnica para o corpus\n",
        "lista_tokens = nltk.tokenize.word_tokenize(artigos)\n",
        "lista_palavras = separa_palavras(lista_tokens)\n",
        "print(f'O número de palavras é {len(lista_palavras)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FlgVfTRucqb",
        "outputId": "524bb18d-ccce-4ae2-b5bc-58059138e6df"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O número de palavras é 403031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# agora temos que contar quantas palavras diferentes temos na lista\n",
        "# antes de contar as palavras diferentes vamos normalizar as palavras para lower case\n",
        "\n",
        "def normalizacao(lista_palavras):\n",
        "  lista_normalizada = []\n",
        "  for palavra in lista_palavras:\n",
        "    lista_normalizada.append(palavra.lower())\n",
        "  return lista_normalizada"
      ],
      "metadata": {
        "id": "Nc73UI_DyJnS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lista_normalizada = normalizacao(lista_palavras)\n",
        "print(lista_normalizada[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JSOcF0H0Ky0",
        "outputId": "7dc5ce8f-f055-4dce-a044-524f0debc6cc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['imagem', 'temos', 'a', 'seguinte', 'classe']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vamos remover as palavras repetidas criando o set\n",
        "# para então contar com len\n",
        "\n",
        "len(set(lista_normalizada))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7pmrdvk0WM6",
        "outputId": "24f2330e-ca28-431a-cc3e-83ceb68f3bbc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18464"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# desenvolvendo o corretor para inserir letra que deixou de ser digitada\n",
        "# a técnica será dividir a palavra em lados esquerdo e direito\n",
        "# e, após, inserir a letra faltante entre esses dois lados\n",
        "\n",
        "palavra_exemplo = 'lgica'\n",
        "\n",
        "def insere_letras(fatias):\n",
        "  novas_palavras = []\n",
        "  letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
        "  for E, D in fatias:\n",
        "    for letra in letras:\n",
        "      novas_palavras.append(E + letra + D)\n",
        "  return novas_palavras\n",
        "\n",
        "def gerador_palavras(palavra):\n",
        "  fatias = []\n",
        "  for i in range(len(palavra)):\n",
        "    fatias.append((palavra[:i],palavra[i:]))\n",
        "  palavras_geradas = insere_letras(fatias)\n",
        "  return palavras_geradas\n",
        "\n",
        "palavras_geradas = gerador_palavras(palavra_exemplo)\n",
        "print(palavras_geradas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCEScdph1C5L",
        "outputId": "d3369db3-cce6-4ad4-ad1e-32d3466b52e6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['algica', 'blgica', 'clgica', 'dlgica', 'elgica', 'flgica', 'glgica', 'hlgica', 'ilgica', 'jlgica', 'klgica', 'llgica', 'mlgica', 'nlgica', 'olgica', 'plgica', 'qlgica', 'rlgica', 'slgica', 'tlgica', 'ulgica', 'vlgica', 'wlgica', 'xlgica', 'ylgica', 'zlgica', 'àlgica', 'álgica', 'âlgica', 'ãlgica', 'èlgica', 'élgica', 'êlgica', 'ìlgica', 'ílgica', 'îlgica', 'òlgica', 'ólgica', 'ôlgica', 'õlgica', 'ùlgica', 'úlgica', 'ûlgica', 'çlgica', 'lagica', 'lbgica', 'lcgica', 'ldgica', 'legica', 'lfgica', 'lggica', 'lhgica', 'ligica', 'ljgica', 'lkgica', 'llgica', 'lmgica', 'lngica', 'logica', 'lpgica', 'lqgica', 'lrgica', 'lsgica', 'ltgica', 'lugica', 'lvgica', 'lwgica', 'lxgica', 'lygica', 'lzgica', 'làgica', 'lágica', 'lâgica', 'lãgica', 'lègica', 'légica', 'lêgica', 'lìgica', 'lígica', 'lîgica', 'lògica', 'lógica', 'lôgica', 'lõgica', 'lùgica', 'lúgica', 'lûgica', 'lçgica', 'lgaica', 'lgbica', 'lgcica', 'lgdica', 'lgeica', 'lgfica', 'lggica', 'lghica', 'lgiica', 'lgjica', 'lgkica', 'lglica', 'lgmica', 'lgnica', 'lgoica', 'lgpica', 'lgqica', 'lgrica', 'lgsica', 'lgtica', 'lguica', 'lgvica', 'lgwica', 'lgxica', 'lgyica', 'lgzica', 'lgàica', 'lgáica', 'lgâica', 'lgãica', 'lgèica', 'lgéica', 'lgêica', 'lgìica', 'lgíica', 'lgîica', 'lgòica', 'lgóica', 'lgôica', 'lgõica', 'lgùica', 'lgúica', 'lgûica', 'lgçica', 'lgiaca', 'lgibca', 'lgicca', 'lgidca', 'lgieca', 'lgifca', 'lgigca', 'lgihca', 'lgiica', 'lgijca', 'lgikca', 'lgilca', 'lgimca', 'lginca', 'lgioca', 'lgipca', 'lgiqca', 'lgirca', 'lgisca', 'lgitca', 'lgiuca', 'lgivca', 'lgiwca', 'lgixca', 'lgiyca', 'lgizca', 'lgiàca', 'lgiáca', 'lgiâca', 'lgiãca', 'lgièca', 'lgiéca', 'lgiêca', 'lgiìca', 'lgiíca', 'lgiîca', 'lgiòca', 'lgióca', 'lgiôca', 'lgiõca', 'lgiùca', 'lgiúca', 'lgiûca', 'lgiçca', 'lgicaa', 'lgicba', 'lgicca', 'lgicda', 'lgicea', 'lgicfa', 'lgicga', 'lgicha', 'lgicia', 'lgicja', 'lgicka', 'lgicla', 'lgicma', 'lgicna', 'lgicoa', 'lgicpa', 'lgicqa', 'lgicra', 'lgicsa', 'lgicta', 'lgicua', 'lgicva', 'lgicwa', 'lgicxa', 'lgicya', 'lgicza', 'lgicàa', 'lgicáa', 'lgicâa', 'lgicãa', 'lgicèa', 'lgicéa', 'lgicêa', 'lgicìa', 'lgicía', 'lgicîa', 'lgicòa', 'lgicóa', 'lgicôa', 'lgicõa', 'lgicùa', 'lgicúa', 'lgicûa', 'lgicça']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# criar a função que verifica as palavras geradas e seleciona a correta\n",
        "# dentro da função max passamos no parametro key uma função que calculará a probabilidade\n",
        "# das palavras, retornando a com maior probabilidade de ser a correta\n",
        "\n",
        "def corretor(palavra):\n",
        "  palavras_geradas = gerador_palavras(palavra)\n",
        "  palavra_correta = max(palavras_geradas, key=probabilidade)\n",
        "  return palavra_correta"
      ],
      "metadata": {
        "id": "FXNRQ5TDndem"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# como calcular a probabilidade = frequencia_palavra/total_de_palavras\n",
        "# primeiro passo encontrar a frequencia das palavras\n",
        "# no nltk tem um método que conta isso\n",
        "\n",
        "frequencia = nltk.FreqDist(lista_normalizada)\n",
        "total_palavras = len(lista_normalizada)\n",
        "frequencia.most_common(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ml-vvqJxVcd-",
        "outputId": "d0cd8d98-efc6-4e5a-aa4c-b2d3bbf3b3bb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('de', 15502),\n",
              " ('o', 14056),\n",
              " ('que', 12230),\n",
              " ('a', 11099),\n",
              " ('e', 10501),\n",
              " ('para', 7710),\n",
              " ('um', 6367),\n",
              " ('é', 5899),\n",
              " ('uma', 5220),\n",
              " ('do', 5124)]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def probabilidade(palavra_gerada):\n",
        "  return frequencia[palavra_gerada]/total_palavras\n",
        "\n",
        "probabilidade('logica')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eA-ou4i7WRdS",
        "outputId": "e47f6e0e-18ef-4799-d9b3-fd62370d5881"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corretor(palavra_exemplo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "7hHUssBfXQQs",
        "outputId": "52691afd-c372-4b17-fb79-bdc20be91ac9"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'lógica'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# até aqui nosso algoritmo corrige apenas um tipo de erro\n",
        "# somente quando um caractere deixa de ser digitado\n",
        "# vamos avaliar nosso modelo\n",
        "\n",
        "# criar uma função que lê uma base de teste e retorna uma lista para ser usada\n",
        "# na função avaliador\n",
        "def cria_dados_teste(nome_arquivo):\n",
        "  lista_palavras_teste = []\n",
        "  f = open(nome_arquivo, 'r')\n",
        "  for linha in f:\n",
        "    correta, errada = linha.split()\n",
        "    lista_palavras_teste.append((correta, errada))\n",
        "  f.close()\n",
        "  return lista_palavras_teste\n",
        "\n",
        "lista_teste = cria_dados_teste('palavras.txt')\n",
        "lista_teste"
      ],
      "metadata": {
        "id": "9-5Za1B1Xu-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def avaliador(testes):\n",
        "  numero_palavras = len(testes)\n",
        "  acertou = 0\n",
        "  for correta, errada in testes:\n",
        "    palavra_corrigida = corretor(errada)\n",
        "    if palavra_corrigida == correta:\n",
        "      acertou += 1\n",
        "  taxa_acerto = round(acertou*100/numero_palavras, 2)\n",
        "  print(f'{taxa_acerto}% de {numero_palavras} palavras')\n",
        "\n",
        "avaliador(lista_teste)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7ZgBGUSageD",
        "outputId": "5636a8d7-7f01-46c6-e1de-659395816f67"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.08% de 186 palavras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# agora vamos incrementar o corretor para corrigir letras a mais na palavra\n",
        "# função que deleta sempre o index zero da fatia da direita\n",
        "\n",
        "def deletando_caracteres(fatias):\n",
        "  novas_palavras = []\n",
        "  for E, D in fatias:\n",
        "    novas_palavras.append(E + D[1:])\n",
        "  return novas_palavras"
      ],
      "metadata": {
        "id": "q-zAjb2WcoGh"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adaptando a função gerador_palavras para deletar caracteres também\n",
        "\n",
        "def gerador_palavras(palavra):\n",
        "  fatias = []\n",
        "  for i in range(len(palavra)):\n",
        "    fatias.append((palavra[:i],palavra[i:]))\n",
        "  palavras_geradas = insere_letras(fatias)\n",
        "  palavras_geradas += deletando_caracteres(fatias)\n",
        "  return palavras_geradas\n",
        "\n",
        "palavra_exemplo = 'lóigica'\n",
        "palavras_geradas = gerador_palavras(palavra_exemplo)\n",
        "print(palavras_geradas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiWlWS_BgOsC",
        "outputId": "850394eb-b0f0-440c-f2ad-be12a18cdb8d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['alóigica', 'blóigica', 'clóigica', 'dlóigica', 'elóigica', 'flóigica', 'glóigica', 'hlóigica', 'ilóigica', 'jlóigica', 'klóigica', 'llóigica', 'mlóigica', 'nlóigica', 'olóigica', 'plóigica', 'qlóigica', 'rlóigica', 'slóigica', 'tlóigica', 'ulóigica', 'vlóigica', 'wlóigica', 'xlóigica', 'ylóigica', 'zlóigica', 'àlóigica', 'álóigica', 'âlóigica', 'ãlóigica', 'èlóigica', 'élóigica', 'êlóigica', 'ìlóigica', 'ílóigica', 'îlóigica', 'òlóigica', 'ólóigica', 'ôlóigica', 'õlóigica', 'ùlóigica', 'úlóigica', 'ûlóigica', 'çlóigica', 'laóigica', 'lbóigica', 'lcóigica', 'ldóigica', 'leóigica', 'lfóigica', 'lgóigica', 'lhóigica', 'lióigica', 'ljóigica', 'lkóigica', 'llóigica', 'lmóigica', 'lnóigica', 'loóigica', 'lpóigica', 'lqóigica', 'lróigica', 'lsóigica', 'ltóigica', 'luóigica', 'lvóigica', 'lwóigica', 'lxóigica', 'lyóigica', 'lzóigica', 'làóigica', 'láóigica', 'lâóigica', 'lãóigica', 'lèóigica', 'léóigica', 'lêóigica', 'lìóigica', 'líóigica', 'lîóigica', 'lòóigica', 'lóóigica', 'lôóigica', 'lõóigica', 'lùóigica', 'lúóigica', 'lûóigica', 'lçóigica', 'lóaigica', 'lóbigica', 'lócigica', 'lódigica', 'lóeigica', 'lófigica', 'lógigica', 'lóhigica', 'lóiigica', 'lójigica', 'lókigica', 'lóligica', 'lómigica', 'lónigica', 'lóoigica', 'lópigica', 'lóqigica', 'lórigica', 'lósigica', 'lótigica', 'lóuigica', 'lóvigica', 'lówigica', 'lóxigica', 'lóyigica', 'lózigica', 'lóàigica', 'lóáigica', 'lóâigica', 'lóãigica', 'lóèigica', 'lóéigica', 'lóêigica', 'lóìigica', 'lóíigica', 'lóîigica', 'lóòigica', 'lóóigica', 'lóôigica', 'lóõigica', 'lóùigica', 'lóúigica', 'lóûigica', 'lóçigica', 'lóiagica', 'lóibgica', 'lóicgica', 'lóidgica', 'lóiegica', 'lóifgica', 'lóiggica', 'lóihgica', 'lóiigica', 'lóijgica', 'lóikgica', 'lóilgica', 'lóimgica', 'lóingica', 'lóiogica', 'lóipgica', 'lóiqgica', 'lóirgica', 'lóisgica', 'lóitgica', 'lóiugica', 'lóivgica', 'lóiwgica', 'lóixgica', 'lóiygica', 'lóizgica', 'lóiàgica', 'lóiágica', 'lóiâgica', 'lóiãgica', 'lóiègica', 'lóiégica', 'lóiêgica', 'lóiìgica', 'lóiígica', 'lóiîgica', 'lóiògica', 'lóiógica', 'lóiôgica', 'lóiõgica', 'lóiùgica', 'lóiúgica', 'lóiûgica', 'lóiçgica', 'lóigaica', 'lóigbica', 'lóigcica', 'lóigdica', 'lóigeica', 'lóigfica', 'lóiggica', 'lóighica', 'lóigiica', 'lóigjica', 'lóigkica', 'lóiglica', 'lóigmica', 'lóignica', 'lóigoica', 'lóigpica', 'lóigqica', 'lóigrica', 'lóigsica', 'lóigtica', 'lóiguica', 'lóigvica', 'lóigwica', 'lóigxica', 'lóigyica', 'lóigzica', 'lóigàica', 'lóigáica', 'lóigâica', 'lóigãica', 'lóigèica', 'lóigéica', 'lóigêica', 'lóigìica', 'lóigíica', 'lóigîica', 'lóigòica', 'lóigóica', 'lóigôica', 'lóigõica', 'lóigùica', 'lóigúica', 'lóigûica', 'lóigçica', 'lóigiaca', 'lóigibca', 'lóigicca', 'lóigidca', 'lóigieca', 'lóigifca', 'lóigigca', 'lóigihca', 'lóigiica', 'lóigijca', 'lóigikca', 'lóigilca', 'lóigimca', 'lóiginca', 'lóigioca', 'lóigipca', 'lóigiqca', 'lóigirca', 'lóigisca', 'lóigitca', 'lóigiuca', 'lóigivca', 'lóigiwca', 'lóigixca', 'lóigiyca', 'lóigizca', 'lóigiàca', 'lóigiáca', 'lóigiâca', 'lóigiãca', 'lóigièca', 'lóigiéca', 'lóigiêca', 'lóigiìca', 'lóigiíca', 'lóigiîca', 'lóigiòca', 'lóigióca', 'lóigiôca', 'lóigiõca', 'lóigiùca', 'lóigiúca', 'lóigiûca', 'lóigiçca', 'lóigicaa', 'lóigicba', 'lóigicca', 'lóigicda', 'lóigicea', 'lóigicfa', 'lóigicga', 'lóigicha', 'lóigicia', 'lóigicja', 'lóigicka', 'lóigicla', 'lóigicma', 'lóigicna', 'lóigicoa', 'lóigicpa', 'lóigicqa', 'lóigicra', 'lóigicsa', 'lóigicta', 'lóigicua', 'lóigicva', 'lóigicwa', 'lóigicxa', 'lóigicya', 'lóigicza', 'lóigicàa', 'lóigicáa', 'lóigicâa', 'lóigicãa', 'lóigicèa', 'lóigicéa', 'lóigicêa', 'lóigicìa', 'lóigicía', 'lóigicîa', 'lóigicòa', 'lóigicóa', 'lóigicôa', 'lóigicõa', 'lóigicùa', 'lóigicúa', 'lóigicûa', 'lóigicça', 'óigica', 'ligica', 'lógica', 'lóiica', 'lóigca', 'lóigia', 'lóigic']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# avaliando o algoritmo com a nova adaptação\n",
        "avaliador(lista_teste)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DryQv_4SiUoQ",
        "outputId": "4bd9f13d-c606-4466-fbca-92c39e9dffed"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41.4% de 186 palavras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uznOp-7Qiu3v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}